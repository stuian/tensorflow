{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "conv1_1\n",
      "weights shape:  (3, 3, 3, 64)\n",
      "biases shape:  (64,)\n",
      "\n",
      "\n",
      "conv1_2\n",
      "weights shape:  (3, 3, 64, 64)\n",
      "biases shape:  (64,)\n",
      "\n",
      "\n",
      "conv2_1\n",
      "weights shape:  (3, 3, 64, 128)\n",
      "biases shape:  (128,)\n",
      "\n",
      "\n",
      "conv2_2\n",
      "weights shape:  (3, 3, 128, 128)\n",
      "biases shape:  (128,)\n",
      "\n",
      "\n",
      "conv3_1\n",
      "weights shape:  (3, 3, 128, 256)\n",
      "biases shape:  (256,)\n",
      "\n",
      "\n",
      "conv3_2\n",
      "weights shape:  (3, 3, 256, 256)\n",
      "biases shape:  (256,)\n",
      "\n",
      "\n",
      "conv3_3\n",
      "weights shape:  (3, 3, 256, 256)\n",
      "biases shape:  (256,)\n",
      "\n",
      "\n",
      "conv4_1\n",
      "weights shape:  (3, 3, 256, 512)\n",
      "biases shape:  (512,)\n",
      "\n",
      "\n",
      "conv4_2\n",
      "weights shape:  (3, 3, 512, 512)\n",
      "biases shape:  (512,)\n",
      "\n",
      "\n",
      "conv4_3\n",
      "weights shape:  (3, 3, 512, 512)\n",
      "biases shape:  (512,)\n",
      "\n",
      "\n",
      "conv5_1\n",
      "weights shape:  (3, 3, 512, 512)\n",
      "biases shape:  (512,)\n",
      "\n",
      "\n",
      "conv5_2\n",
      "weights shape:  (3, 3, 512, 512)\n",
      "biases shape:  (512,)\n",
      "\n",
      "\n",
      "conv5_3\n",
      "weights shape:  (3, 3, 512, 512)\n",
      "biases shape:  (512,)\n",
      "\n",
      "\n",
      "fc6\n",
      "weights shape:  (25088, 4096)\n",
      "biases shape:  (4096,)\n",
      "\n",
      "\n",
      "fc7\n",
      "weights shape:  (4096, 4096)\n",
      "biases shape:  (4096,)\n",
      "\n",
      "\n",
      "fc8\n",
      "weights shape:  (4096, 1000)\n",
      "biases shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import test_cifar\n",
    "import architecture\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_W = 32\n",
    "IMG_H = 32\n",
    "N_CLASSES = 10\n",
    "BATCH_SIZE = 24\n",
    "learning_rate = 0.01\n",
    "MAX_STEP = 15001   \n",
    "IS_PRETRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    pre_trained_weights = '../vgg16.npy'\n",
    "    data_dir = '../../data/cifar-10-batches-bin/'\n",
    "    train_log_dir = 'logs/train/'\n",
    "    val_log_dir = 'logs/val/'\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        tra_image_batch, tra_label_batch = test_cifar.read_cifar10(data_dir=data_dir,\n",
    "                                                 is_train=True,\n",
    "                                                 batch_size= BATCH_SIZE,\n",
    "                                                 shuffle=True)\n",
    "        val_image_batch, val_label_batch = test_cifar.read_cifar10(data_dir=data_dir,\n",
    "                                                 is_train=False,\n",
    "                                                 batch_size= BATCH_SIZE,\n",
    "                                                 shuffle=False)\n",
    "        \n",
    "    x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_W, IMG_H, 3])\n",
    "    y_ = tf.placeholder(tf.int16, shape=[BATCH_SIZE, N_CLASSES]) \n",
    "    \n",
    "    logits = architecture.VGG16N(x, N_CLASSES, IS_PRETRAIN)\n",
    "    loss = tools.loss(logits, y_)\n",
    "    accuracy = tools.accuracy(logits, y_)\n",
    "    \n",
    "    my_global_step = tf.Variable(0, name='global_step', trainable=False) \n",
    "    train_op = tools.optimize(loss, learning_rate, my_global_step)   \n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    summary_op = tf.summary.merge_all()   \n",
    "       \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # load the parameter file, assign the parameters, skip the specific layers\n",
    "    tools.load_with_skip(pre_trained_weights, sess, ['fc6','fc7','fc8'])   \n",
    "\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    \n",
    "    tra_summary_writer = tf.summary.FileWriter(train_log_dir, sess.graph)\n",
    "    val_summary_writer = tf.summary.FileWriter(val_log_dir, sess.graph)\n",
    "    \n",
    "    try:\n",
    "        for step in np.arange(MAX_STEP):\n",
    "            if coord.should_stop():\n",
    "                    break\n",
    "                \n",
    "            tra_images,tra_labels = sess.run([tra_image_batch, tra_label_batch])\n",
    "            _, tra_loss, tra_acc = sess.run([train_op, loss, accuracy],\n",
    "                                            feed_dict={x:tra_images, y_:tra_labels})            \n",
    "            if step % 50 == 0:                 \n",
    "                print ('Step: %d, loss: %.4f, accuracy: %.4f%%' % (step, tra_loss, tra_acc))\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                      feed_dict={x:tra_images, y_:tra_labels})\n",
    "                tra_summary_writer.add_summary(summary_str, step)\n",
    "                \n",
    "            if step % 200 == 0:\n",
    "                val_images, val_labels = sess.run([val_image_batch, val_label_batch])\n",
    "                val_loss, val_acc = sess.run([loss, accuracy],\n",
    "                                             feed_dict={x:val_images,y_:val_labels})\n",
    "                print('**  Step %d, val loss = %.2f, val accuracy = %.2f%%  **' %(step, val_loss, val_acc))\n",
    "\n",
    "                summary_str = sess.run(summary_op,\n",
    "                                      feed_dict={x:val_images, y_:val_labels})\n",
    "                val_summary_writer.add_summary(summary_str, step)\n",
    "                    \n",
    "            if step % 2000 == 0:\n",
    "                checkpoint_path = os.path.join(train_log_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "                \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "        \n",
    "    coord.join(threads)\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, loss: 3.0521, accuracy: 0.0000%\n",
      "**  Step 0, val loss = 2.50, val accuracy = 8.33%  **\n",
      "Step: 50, loss: 2.2929, accuracy: 12.5000%\n",
      "Step: 100, loss: 2.6431, accuracy: 0.0000%\n",
      "Step: 150, loss: 2.3864, accuracy: 12.5000%\n",
      "Step: 200, loss: 2.3982, accuracy: 12.5000%\n",
      "**  Step 200, val loss = 2.57, val accuracy = 4.17%  **\n",
      "Step: 250, loss: 2.4337, accuracy: 16.6667%\n",
      "Step: 300, loss: 2.3135, accuracy: 25.0000%\n",
      "Step: 350, loss: 2.3513, accuracy: 12.5000%\n",
      "Step: 400, loss: 2.3043, accuracy: 12.5000%\n",
      "**  Step 400, val loss = 2.43, val accuracy = 16.67%  **\n",
      "Step: 450, loss: 2.4233, accuracy: 12.5000%\n",
      "Step: 500, loss: 2.2049, accuracy: 8.3333%\n",
      "Step: 550, loss: 2.2559, accuracy: 12.5000%\n",
      "Step: 600, loss: 2.2676, accuracy: 25.0000%\n",
      "**  Step 600, val loss = 2.36, val accuracy = 16.67%  **\n",
      "Step: 650, loss: 2.3372, accuracy: 8.3333%\n",
      "Step: 700, loss: 2.5736, accuracy: 8.3333%\n",
      "Step: 750, loss: 2.4977, accuracy: 16.6667%\n",
      "Step: 800, loss: 2.3906, accuracy: 12.5000%\n",
      "**  Step 800, val loss = 2.33, val accuracy = 16.67%  **\n",
      "Step: 850, loss: 2.5416, accuracy: 12.5000%\n",
      "Step: 900, loss: 2.3441, accuracy: 4.1667%\n",
      "Step: 950, loss: 2.2637, accuracy: 16.6667%\n",
      "Step: 1000, loss: 2.1455, accuracy: 29.1667%\n",
      "**  Step 1000, val loss = 2.82, val accuracy = 16.67%  **\n",
      "Step: 1050, loss: 2.2157, accuracy: 25.0000%\n",
      "Step: 1100, loss: 2.1879, accuracy: 8.3333%\n",
      "Step: 1150, loss: 2.3120, accuracy: 29.1667%\n",
      "Step: 1200, loss: 2.5367, accuracy: 12.5000%\n",
      "**  Step 1200, val loss = 2.39, val accuracy = 12.50%  **\n",
      "Step: 1250, loss: 1.8712, accuracy: 33.3333%\n",
      "Step: 1300, loss: 2.2651, accuracy: 8.3333%\n",
      "Step: 1350, loss: 2.4516, accuracy: 20.8333%\n",
      "Step: 1400, loss: 2.2481, accuracy: 41.6667%\n",
      "**  Step 1400, val loss = 2.05, val accuracy = 29.17%  **\n",
      "Step: 1450, loss: 2.0002, accuracy: 25.0000%\n",
      "Step: 1500, loss: 2.4816, accuracy: 16.6667%\n",
      "Step: 1550, loss: 2.0943, accuracy: 20.8333%\n",
      "Step: 1600, loss: 1.9418, accuracy: 20.8333%\n",
      "**  Step 1600, val loss = 2.52, val accuracy = 16.67%  **\n",
      "Step: 1650, loss: 2.0171, accuracy: 29.1667%\n",
      "Step: 1700, loss: 1.8923, accuracy: 33.3333%\n",
      "Step: 1750, loss: 2.2885, accuracy: 8.3333%\n",
      "Step: 1800, loss: 2.3021, accuracy: 16.6667%\n",
      "**  Step 1800, val loss = 2.21, val accuracy = 25.00%  **\n",
      "Step: 1850, loss: 2.0533, accuracy: 12.5000%\n",
      "Step: 1900, loss: 1.9878, accuracy: 29.1667%\n",
      "Step: 1950, loss: 2.1301, accuracy: 37.5000%\n",
      "Step: 2000, loss: 2.1712, accuracy: 12.5000%\n",
      "**  Step 2000, val loss = 2.17, val accuracy = 25.00%  **\n",
      "Step: 2050, loss: 2.2171, accuracy: 20.8333%\n",
      "Step: 2100, loss: 2.4424, accuracy: 16.6667%\n",
      "Step: 2150, loss: 1.6082, accuracy: 37.5000%\n",
      "Step: 2200, loss: 2.1800, accuracy: 16.6667%\n",
      "**  Step 2200, val loss = 2.35, val accuracy = 25.00%  **\n",
      "Step: 2250, loss: 2.1806, accuracy: 12.5000%\n",
      "Step: 2300, loss: 1.9820, accuracy: 33.3333%\n",
      "Step: 2350, loss: 1.8081, accuracy: 33.3333%\n",
      "Step: 2400, loss: 1.8485, accuracy: 25.0000%\n",
      "**  Step 2400, val loss = 2.21, val accuracy = 25.00%  **\n",
      "Step: 2450, loss: 1.9960, accuracy: 25.0000%\n",
      "Step: 2500, loss: 2.3657, accuracy: 12.5000%\n",
      "Step: 2550, loss: 2.5102, accuracy: 16.6667%\n",
      "Step: 2600, loss: 2.4901, accuracy: 20.8333%\n",
      "**  Step 2600, val loss = 2.17, val accuracy = 29.17%  **\n",
      "Step: 2650, loss: 1.8678, accuracy: 20.8333%\n",
      "Step: 2700, loss: 2.2120, accuracy: 20.8333%\n",
      "Step: 2750, loss: 1.9684, accuracy: 33.3333%\n",
      "Step: 2800, loss: 1.8846, accuracy: 29.1667%\n",
      "**  Step 2800, val loss = 1.81, val accuracy = 33.33%  **\n",
      "Step: 2850, loss: 1.7996, accuracy: 29.1667%\n",
      "Step: 2900, loss: 2.1501, accuracy: 33.3333%\n",
      "Step: 2950, loss: 1.7768, accuracy: 45.8333%\n",
      "Step: 3000, loss: 1.9839, accuracy: 37.5000%\n",
      "**  Step 3000, val loss = 2.19, val accuracy = 25.00%  **\n",
      "Step: 3050, loss: 1.8522, accuracy: 25.0000%\n",
      "Step: 3100, loss: 1.8710, accuracy: 45.8333%\n",
      "Step: 3150, loss: 2.2724, accuracy: 16.6667%\n",
      "Step: 3200, loss: 2.2635, accuracy: 25.0000%\n",
      "**  Step 3200, val loss = 2.17, val accuracy = 16.67%  **\n",
      "Step: 3250, loss: 1.9857, accuracy: 25.0000%\n",
      "Step: 3300, loss: 1.6416, accuracy: 41.6667%\n",
      "Step: 3350, loss: 1.8290, accuracy: 29.1667%\n",
      "Step: 3400, loss: 1.9129, accuracy: 29.1667%\n",
      "**  Step 3400, val loss = 1.82, val accuracy = 33.33%  **\n",
      "Step: 3450, loss: 1.6012, accuracy: 33.3333%\n",
      "Step: 3500, loss: 2.0904, accuracy: 29.1667%\n",
      "Step: 3550, loss: 2.2701, accuracy: 8.3333%\n",
      "Step: 3600, loss: 1.9589, accuracy: 12.5000%\n",
      "**  Step 3600, val loss = 1.91, val accuracy = 33.33%  **\n",
      "Step: 3650, loss: 2.2798, accuracy: 25.0000%\n",
      "Step: 3700, loss: 2.5670, accuracy: 25.0000%\n",
      "Step: 3750, loss: 1.8018, accuracy: 16.6667%\n",
      "Step: 3800, loss: 2.3426, accuracy: 20.8333%\n",
      "**  Step 3800, val loss = 2.24, val accuracy = 12.50%  **\n",
      "Step: 3850, loss: 2.0384, accuracy: 20.8333%\n",
      "Step: 3900, loss: 1.8073, accuracy: 37.5000%\n",
      "Step: 3950, loss: 2.0085, accuracy: 33.3333%\n",
      "Step: 4000, loss: 1.5728, accuracy: 45.8333%\n",
      "**  Step 4000, val loss = 1.65, val accuracy = 45.83%  **\n",
      "Step: 4050, loss: 2.0120, accuracy: 20.8333%\n",
      "Step: 4100, loss: 1.3125, accuracy: 54.1667%\n",
      "Step: 4150, loss: 1.8028, accuracy: 20.8333%\n",
      "Step: 4200, loss: 1.9957, accuracy: 25.0000%\n",
      "**  Step 4200, val loss = 1.52, val accuracy = 50.00%  **\n",
      "Step: 4250, loss: 1.4705, accuracy: 54.1667%\n",
      "Step: 4300, loss: 1.5864, accuracy: 37.5000%\n",
      "Step: 4350, loss: 1.6623, accuracy: 41.6667%\n",
      "Step: 4400, loss: 2.4445, accuracy: 25.0000%\n",
      "**  Step 4400, val loss = 1.66, val accuracy = 20.83%  **\n",
      "Step: 4450, loss: 1.5798, accuracy: 45.8333%\n",
      "Step: 4500, loss: 1.3835, accuracy: 37.5000%\n",
      "Step: 4550, loss: 1.6464, accuracy: 33.3333%\n",
      "Step: 4600, loss: 1.7298, accuracy: 41.6667%\n",
      "**  Step 4600, val loss = 1.82, val accuracy = 25.00%  **\n",
      "Step: 4650, loss: 2.3894, accuracy: 25.0000%\n",
      "Step: 4700, loss: 2.1470, accuracy: 33.3333%\n",
      "Step: 4750, loss: 2.2616, accuracy: 12.5000%\n",
      "Step: 4800, loss: 2.2800, accuracy: 16.6667%\n",
      "**  Step 4800, val loss = 2.40, val accuracy = 12.50%  **\n",
      "Step: 4850, loss: 2.2706, accuracy: 29.1667%\n",
      "Step: 4900, loss: 2.2846, accuracy: 20.8333%\n",
      "Step: 4950, loss: 2.2801, accuracy: 8.3333%\n",
      "Step: 5000, loss: 1.8153, accuracy: 41.6667%\n",
      "**  Step 5000, val loss = 1.52, val accuracy = 37.50%  **\n",
      "Step: 5050, loss: 2.0514, accuracy: 16.6667%\n",
      "Step: 5100, loss: 2.3202, accuracy: 20.8333%\n",
      "Step: 5150, loss: 2.3988, accuracy: 12.5000%\n",
      "Step: 5200, loss: 2.7436, accuracy: 8.3333%\n",
      "**  Step 5200, val loss = 2.61, val accuracy = 0.00%  **\n",
      "Step: 5250, loss: 2.2927, accuracy: 20.8333%\n",
      "Step: 5300, loss: 2.2292, accuracy: 20.8333%\n",
      "Step: 5350, loss: 2.2482, accuracy: 8.3333%\n",
      "Step: 5400, loss: 2.3584, accuracy: 8.3333%\n",
      "**  Step 5400, val loss = 2.34, val accuracy = 12.50%  **\n",
      "Step: 5450, loss: 2.3987, accuracy: 16.6667%\n",
      "Step: 5500, loss: 2.3890, accuracy: 12.5000%\n",
      "Step: 5550, loss: 2.2689, accuracy: 16.6667%\n",
      "Step: 5600, loss: 2.1744, accuracy: 25.0000%\n",
      "**  Step 5600, val loss = 2.51, val accuracy = 8.33%  **\n",
      "Step: 5650, loss: 2.3904, accuracy: 8.3333%\n",
      "Step: 5700, loss: 2.2188, accuracy: 16.6667%\n",
      "Step: 5750, loss: 2.2403, accuracy: 16.6667%\n",
      "Step: 5800, loss: 2.6015, accuracy: 12.5000%\n",
      "**  Step 5800, val loss = 2.11, val accuracy = 33.33%  **\n",
      "Step: 5850, loss: 2.2655, accuracy: 12.5000%\n",
      "Step: 5900, loss: 2.2355, accuracy: 29.1667%\n",
      "Step: 5950, loss: 2.2994, accuracy: 12.5000%\n",
      "Step: 6000, loss: 2.4055, accuracy: 16.6667%\n",
      "**  Step 6000, val loss = 2.59, val accuracy = 4.17%  **\n",
      "Step: 6050, loss: 2.2585, accuracy: 29.1667%\n",
      "Step: 6100, loss: 2.3787, accuracy: 29.1667%\n",
      "Step: 6150, loss: 2.4844, accuracy: 8.3333%\n",
      "Step: 6200, loss: 2.4486, accuracy: 4.1667%\n",
      "**  Step 6200, val loss = 2.63, val accuracy = 12.50%  **\n",
      "Step: 6250, loss: 2.2504, accuracy: 12.5000%\n",
      "Step: 6300, loss: 2.3946, accuracy: 12.5000%\n",
      "Step: 6350, loss: 2.0518, accuracy: 33.3333%\n",
      "Step: 6400, loss: 2.2493, accuracy: 16.6667%\n",
      "**  Step 6400, val loss = 2.55, val accuracy = 20.83%  **\n",
      "Step: 6450, loss: 2.4909, accuracy: 12.5000%\n",
      "Step: 6500, loss: 2.3170, accuracy: 16.6667%\n",
      "Step: 6550, loss: 2.2991, accuracy: 12.5000%\n",
      "Step: 6600, loss: 2.5145, accuracy: 12.5000%\n",
      "**  Step 6600, val loss = 2.11, val accuracy = 29.17%  **\n",
      "Step: 6650, loss: 2.5421, accuracy: 8.3333%\n",
      "Step: 6700, loss: 2.4498, accuracy: 12.5000%\n",
      "Step: 6750, loss: 2.5175, accuracy: 20.8333%\n",
      "Step: 6800, loss: 2.1405, accuracy: 12.5000%\n",
      "**  Step 6800, val loss = 2.36, val accuracy = 8.33%  **\n",
      "Step: 6850, loss: 2.9344, accuracy: 12.5000%\n",
      "Step: 6900, loss: 2.2270, accuracy: 8.3333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6950, loss: 2.1834, accuracy: 12.5000%\n",
      "Step: 7000, loss: 2.4980, accuracy: 29.1667%\n",
      "**  Step 7000, val loss = 2.16, val accuracy = 41.67%  **\n",
      "Step: 7050, loss: 2.2742, accuracy: 4.1667%\n",
      "Step: 7100, loss: 2.5744, accuracy: 8.3333%\n",
      "Step: 7150, loss: 2.3694, accuracy: 12.5000%\n",
      "Step: 7200, loss: 2.9421, accuracy: 0.0000%\n",
      "**  Step 7200, val loss = 2.32, val accuracy = 8.33%  **\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
