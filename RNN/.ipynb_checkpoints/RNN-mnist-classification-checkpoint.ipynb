{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed = 318):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# Question1:reset_graph(seed=318)函数的两个作用？\n",
    "# 清除默认图的堆栈，并设置全局图为默认图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../CNN/data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ../CNN/data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../CNN/data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../CNN/data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../CNN/data/mnist', one_hot=True)\n",
    "# Question2:\n",
    "# 2.1、train, validation, test的大小；\n",
    "\n",
    "# 2.2、train集合里images、labels的shape\n",
    "\n",
    "# Question3：\n",
    "# 3.1 one_hot=False时，train集合里labels的shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]]))\n"
     ]
    }
   ],
   "source": [
    "# print(mnist.train.epochs_completed)\n",
    "# print(mnist.train.images.shape)\n",
    "# print(mnist.train.labels.shape)\n",
    "print(mnist.train.next_batch(10))\n",
    "# print(mnist.train.num_examples)\n",
    "# print(mnist.test.images.shape)\n",
    "# print(mnist.validation.images.shape)\n",
    "# print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "img_channels = 1\n",
    "img_classes = 10\n",
    "\n",
    "# neural network\n",
    "n_steps = img_height\n",
    "n_inputs = img_width\n",
    "n_neurons = 20\n",
    "n_outputs = img_classes\n",
    "\n",
    "# other hyperparameters\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholer variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "# Question 4: reset_graph()的位置能否再向下移？\n",
    "# 不能，否则建立的图又会被删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "\n",
    "# Question 5: 当one_hot == False时，placeholder variable y该如何定义？\n",
    "# y = tf.placeholder(tf.float32,[None,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(n_neurons, activation = tf.nn.tanh)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, x, dtype = tf.float32)\n",
    "\n",
    "# Output Layer\n",
    "logits = tf.layers.dense(states, n_outputs, activation = tf.nn.softmax)\n",
    "\n",
    "# Question 6：\n",
    "# 6.1 什么是python的序列解包？\n",
    "# 1、一般情况 2、元祖序列解包 3、列表序列解包 4、字典序列解包\n",
    "# 6.2 描述一下该网络的拓扑结构。\n",
    "# 总线性拓扑结构\n",
    "# 6.3 tf.contrib module是各什么性质的模块？\n",
    "# 高阶API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Question 7：\n",
    "# 7.1 当Output layer的activation=None时，cross_entropy该使用哪个函数来替代tf.nn.softmax_cross_entropy_with_logits()？\n",
    "# 最小二倍差？\n",
    "# 7.2 在tf.nn.softmax_cross_entropy_with_logits()函数里，为何使用命名参数？\n",
    "# 区分预测值和参考值？\n",
    "# hints：1）交叉熵损失确切定义；2）交叉熵为什么这样定义？3）避免传错参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer & train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(y, 1), tf.argmax(logits, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "# Question 8：\n",
    "# 8.1 解释计算得到correct向量的过程。\n",
    "# 8.2 为何要用tf.cast()函数？\n",
    "# 把布尔值转变成数字\n",
    "# 8.3 one_hot = False时，给出正确得到correct tensor的代码。\n",
    "# correct = tf.nn.in_top_k(prediction,y,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1001\n",
    "batch_size = 20\n",
    "\n",
    "# Quesiton8：\n",
    "# 8.1 batch_size大小对模型占用的显存或内存是否有影响？\n",
    "# 有\n",
    "# 8.2 n_pochs取1000不好么？\n",
    "# 含头不含尾\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 统计量\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "acc_summary = tf.summary.scalar('acc', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# 保存统计信息的磁盘文件\n",
    "logdir = '../log_dir'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "# build check points\n",
    "checkpoints_path = '../mnist_models'\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0; train_acc = 0.0; test_acc = 0.05000000074505806\n",
      "epoch = 100; train_acc = 0.05000000074505806; test_acc = 0.05000000074505806\n",
      "epoch = 200; train_acc = 0.10000000149011612; test_acc = 0.05000000074505806\n",
      "epoch = 300; train_acc = 0.10000000149011612; test_acc = 0.10000000149011612\n",
      "epoch = 400; train_acc = 0.15000000596046448; test_acc = 0.15000000596046448\n",
      "epoch = 500; train_acc = 0.25; test_acc = 0.30000001192092896\n",
      "epoch = 600; train_acc = 0.20000000298023224; test_acc = 0.25\n",
      "epoch = 700; train_acc = 0.10000000149011612; test_acc = 0.25\n",
      "epoch = 800; train_acc = 0.20000000298023224; test_acc = 0.15000000596046448\n",
      "epoch = 900; train_acc = 0.25; test_acc = 0.20000000298023224\n",
      "epoch = 1000; train_acc = 0.05000000074505806; test_acc = 0.15000000596046448\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "#     saver.restore(sess, checkpoints_path)\n",
    "# Question 9:\n",
    "#     9.1 何时注释掉sess.run(init)？\n",
    "#     接着上次的checkpoints运行时\n",
    "#     9.2 何时注释掉saver.restore(sess, checkpoints_path)？\n",
    "#     最开始运行时\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # for training\n",
    "        x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        x_batch_rnn = np.reshape(x_batch, [-1, n_steps, n_inputs])\n",
    "#         Question 10:\n",
    "#             10.1 为何需要np.reshape()?顺便解释该程序用rnn来训练字符识别时，输入数据时怎样流入计算图的？\n",
    "#              使得输入维度匹配模型的输入，每一行每一行的输入，n_steps等于图片高度\n",
    "#             10.2 解释将np.reshape()更换成tf.reshape()出错的原因？\n",
    "#             tf.reshape()的结果是一个tensor，不能作为输入\n",
    "            \n",
    "        train_acc, _ = sess.run([accuracy, train], feed_dict = {x: x_batch_rnn, y: y_batch})\n",
    "        \n",
    "        # for testing\n",
    "        x_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        x_batch_rnn = np.reshape(x_batch, [-1, n_steps, n_inputs])\n",
    "        [merged_str, test_acc] = sess.run([merged, accuracy],\n",
    "                           feed_dict = {x:x_batch_rnn, y: y_batch})\n",
    "        file_writer.add_summary(merged_str, epoch)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'epoch = {epoch}; train_acc = {train_acc}; test_acc = {test_acc}')\n",
    "        \n",
    "    saver.save(sess, checkpoints_path)\n",
    "# Question 11:\n",
    "# 11.1将上一行代码取消缩进，直接顶格，会出现错误，解释错误原因？\n",
    "# 必须在会话运行的时候才能保存图\n",
    "# 11.2将上一行代码增加缩进量，放到for epoch in range(n_epochs)循环，为什么不好？\n",
    "# 每次循环都保存checkpoints，增加内存\n",
    "\n",
    "file_writer.close()\n",
    "\n",
    "# Question 12：\n",
    "# 12.1 给出Jupyter notebook将代码分成小的cell的优点？\n",
    "# 边写代码边运行\n",
    "# 12.2 给出Jupyter notebook将代码分成小的cell的缺点？\n",
    "# 要一个一个运行，比较麻烦\n",
    "# 12.3 如何避免在jupyter notebook里，错误已经修改正确，代码依然会出现bug？\n",
    "# 重新运行已经修改过的代码\n",
    "# 12.4 在本例代码中，从“models”下面的cell重新执行代码会出错，而从“placeholer variables”下面的cell开始重新执行代码则无错。\n",
    "# 结合出错信息，对照在MLP、CNN程序中是否也会又类似错误。寻找现象差异的原因？\n",
    "# 本代码中错误提示：outputs,states那一行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
